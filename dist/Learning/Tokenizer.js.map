{"version":3,"sources":["Learning/Tokenizer.js"],"names":[],"mappings":";;;;;;;;;;IAAM,S;AAEJ,qBAAY,MAAZ,EAAoB,WAApB,EAAiC;AAAA;;AAC/B,SAAK,OAAL,GAAe,MAAf;AACA,SAAK,YAAL,GAAoB,WAApB;AACD;;;;6BAEQ,M,EAAQ;AACf,UAAI,QAAQ,EAAZ;;AADe;AAAA;AAAA;;AAAA;AAGf,6BAAc,OAAO,KAAP,CAAa,GAAb,CAAd,8HAAiC;AAAA,cAAxB,CAAwB;;AAC/B,cAAI,OAAO,IAAX;AAD+B;AAAA;AAAA;;AAAA;AAE/B,kCAAmB,KAAK,OAAxB,mIAAiC;AAAA,kBAAxB,MAAwB;;AAC/B,kBAAI,CAAC,OAAO,MAAP,CAAc,CAAd,CAAL,EAAuB;AACrB,uBAAO,KAAP;AACA;AACD;AACF;AAP8B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAS/B,cAAI,CAAC,IAAL,EACI;;AAV2B;AAAA;AAAA;;AAAA;AAY/B,kCAAwB,KAAK,YAA7B,mIAA2C;AAAA,kBAAlC,WAAkC;;AACzC,kBAAI,YAAY,SAAZ,CAAsB,CAAtB,CAAJ;AACD;AAd8B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAgB/B,gBAAM,IAAN,CAAW,CAAX;AACD;AApBc;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAsBf,aAAO,KAAP;AACD;;;;;;kBAIY,S","file":"Learning/Tokenizer.js","sourcesContent":["class Tokenizer {\n\n  constructor(filter, transformer) {\n    this._filter = filter;\n    this._transformer = transformer;\n  }\n\n  tokenize(phrase) {\n    let token = [];\n\n    for (let t of phrase.split(' ')) {\n      let keep = true;\n      for (let filter of this._filter) {\n        if (!filter.filter(t)) {\n          keep = false;\n          break;\n        }\n      }\n\n      if (!keep)\n          continue;\n\n      for (let transformer of this._transformer) {\n        t = transformer.transform(t);\n      }\n\n      token.push(t);\n    }\n\n    return token;\n  }\n\n}\n\nexport default Tokenizer;\n"],"sourceRoot":"d:\\Workspace\\jkgaming\\jarvis\\src"}