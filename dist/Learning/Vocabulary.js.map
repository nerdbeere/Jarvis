{"version":3,"sources":["Learning/Vocabulary.js"],"names":[],"mappings":";;;;;;;;;;IAAM,U;AAEJ,sBAAY,SAAZ,EAAuB;AAAA;;AACrB,SAAK,UAAL,GAAkB,SAAlB;AACA,SAAK,MAAL,GAAc,EAAd;AACD;;;;uCAUkB,M,EAAQ;AAAA;AAAA;AAAA;;AAAA;AACzB,6BAAkB,KAAK,UAAL,CAAgB,QAAhB,CAAyB,MAAzB,CAAlB,8HAAoD;AAAA,cAA3C,KAA2C;;AAClD,eAAK,QAAL,CAAc,KAAd;AACD;AAHwB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAI1B;;;6BAEQ,K,EAAO;AACd,UAAI,KAAK,QAAL,CAAc,KAAd,IAAuB,CAAC,CAA5B,EACI;AACJ,WAAK,MAAL,CAAY,IAAZ,CAAiB,KAAjB;AACD;;;6BAEQ,K,EAAO;AACd,aAAO,KAAK,MAAL,CAAY,KAAZ,CAAP;AACD;;;6BAEQ,K,EAAO;AACd,aAAO,KAAK,MAAL,CAAY,OAAZ,CAAoB,KAApB,CAAP;AACD;;;8BAES,K,EAAO;AACf,UAAI,SAAS,EAAb;AACA,WAAK,IAAI,IAAI,CAAb,EAAgB,IAAI,KAAK,MAAL,CAAY,MAAhC,EAAwC,GAAxC,EAA6C;AAC3C,eAAO,CAAP,IAAY,KAAK,MAAL,CAAY,CAAZ,MAAmB,KAAnB,GAA2B,CAA3B,GAA+B,CAA3C;AACD;;AAED,aAAO,MAAP;AACD;;;wCAEmB,M,EAAQ;AAC1B,UAAI,SAAS,EAAb;AACA,UAAI,QAAQ,KAAK,UAAL,CAAgB,QAAhB,CAAyB,MAAzB,CAAZ;;AAEA,WAAK,IAAI,IAAI,CAAb,EAAgB,IAAI,KAAK,MAAL,CAAY,MAAhC,EAAwC,GAAxC,EAA6C;AAC3C,eAAO,CAAP,IAAY,MAAM,OAAN,CAAc,KAAK,MAAL,CAAY,CAAZ,CAAd,IAAgC,CAAC,CAAjC,GAAqC,CAArC,GAAyC,CAArD;AACD;;AAED,aAAO,MAAP;AACD;;;wBA9CW;AACV,aAAO,KAAK,MAAZ;AACD;;;wBAEY;AACX,aAAO,KAAK,MAAL,CAAY,MAAnB;AACD;;;;;;kBA4CY,U","file":"Learning/Vocabulary.js","sourcesContent":["class Vocabulary {\n\n  constructor(tokenizer) {\n    this._tokenizer = tokenizer;\n    this._token = [];\n  }\n\n  get token() {\n    return this._token;\n  }\n\n  get length() {\n    return this._token.length;\n  }\n\n  addTokenFromPhrase(phrase) {\n    for (let token of this._tokenizer.tokenize(phrase)) {\n      this.addToken(token);\n    }\n  }\n\n  addToken(token) {\n    if (this.getIndex(token) > -1)\n        return;\n    this._token.push(token);\n  }\n\n  getToken(index) {\n    return this._token[index];\n  }\n\n  getIndex(token) {\n    return this._token.indexOf(token);\n  }\n\n  getVector(token) {\n    var vector = [];\n    for (let i = 0; i < this._token.length; i++) {\n      vector[i] = this._token[i] === token ? 1 : 0;\n    }\n\n    return vector;\n  }\n\n  getVectorFromPhrase(phrase) {\n    var vector = [];\n    var token = this._tokenizer.tokenize(phrase);\n\n    for (let i = 0; i < this._token.length; i++) {\n      vector[i] = token.indexOf(this._token[i]) > -1 ? 1 : 0;\n    }\n\n    return vector;\n  }\n\n}\n\nexport default Vocabulary;\n"],"sourceRoot":"d:\\Workspace\\jkgaming\\jarvis\\src"}